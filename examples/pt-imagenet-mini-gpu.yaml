# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: batch/v1beta1
kind: CronJob
metadata:
  # TODO: Change this to a unique name within your project.
  name: pt-imagenet-mini-gpu
spec:
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      # TODO: Set the number of retries before marking test as failed.
      backoffLimit: 2
      template:
        spec:
          # TODO: Extend the timeout if your test takes longer.
          activeDeadlineSeconds: 3600
          restartPolicy: Never
          nodeSelector:
            cloud.google.com/gke-accelerator: "nvidia-tesla-v100"
          volumes:
          - name: dshm
            emptyDir:
              medium: Memory
          # TODO: This should match `name` under volumeMounts below.
          - name: "imagenet-mini-pd"
            gcePersistentDisk:
              # TODO: Change this to the name of your Cloud persistent disk.
              pdName: "imagenet-mini-pd-central1-b"
              fsType: "ext4"
              readOnly: true
          containers:
          - name: "train-container"
            # TODO: Change this to your image if desired. See `images/README`
            # for more on setting up images.
            image: "gcr.io/xl-ml-test/pytorch-examples-gpu:latest"
            imagePullPolicy: Always
            resources:
              limits:
                # TODO: Change number of GPUs (if desired).
                nvidia.com/gpu: 1
            volumeMounts:
            - name: dshm
              mountPath: "/dev/shm"
            # TODO: This should match `name` of the gcePersistentDisk above.
            - name: imagenet-mini-pd
              mountPath: "/datasets"
              readOnly: true
            args:
            # TODO: Change this to the command to run your test.
            - "python3"
            - "examples/imagenet/main.py"
            - "--a=resnet18"
            - "/datasets/imagenet-mini"
            - "--epochs=3"
            - "--multiprocessing-distributed"
            - "--dist-url=tcp://localhost:23456"
            - "--rank=0"
            - "--world-size=1"
            env:
            - name: "POD_NAME"
              valueFrom:
                fieldRef:
                  fieldPath: "metadata.name"
            - name: "POD_UID"
              valueFrom:
                fieldRef:
                  fieldPath: "metadata.uid"
            - name: "POD_NAMESPACE"
              valueFrom:
                fieldRef:
                  fieldPath: "metadata.namespace"
            - name: "JOB_NAME"
              valueFrom:
                fieldRef:
                  fieldPath: "metadata.labels['job-name']"
            - name: "MODEL_DIR"
              # TODO: This is where checkpoints and Tensorboard summary files
              # will be written. At the very least, change the storage bucket
              # name away from `xl-ml-test-us-central1` since you won't have
              # write access to that bucket.
              value: "gs://xl-ml-test-us-central1/k8s/imagenet/functional/gpu/$(JOB_NAME)"
            - name: "TEST_NAME"
              # TODO: Recommended to match with `name` from `metadata` above.
              value: "pt-imagenet-mini-gpu"
              # TODO: See `metrics_handler/README` if you want to change these
              # configs. These are used to determine how metrics are collected
              # for your test and how alerts will be generated.
            - name: "METRIC_COLLECTION_CONFIG"
              value: |
                {
                  "write_to_bigquery": "True",
                  "default_aggregation_strategies": ["final"]
                }
            - name: "REGRESSION_TEST_CONFIG"
              value: |
                {
                  "write_to_error_reporting": "True",
                  "metric_success_conditions": {
                    "total_wall_time": {
                      "comparison": "less",
                      "success_threshold": {
                        "stddevs_from_mean": 4.0
                      },
                      "wait_for_n_points_of_history": 10
                    }
                  }
                }
  # TODO: Update the timing of your test runs:
  # https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#schedule
  schedule: "0 */24 * * *"

